{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 4"
      ],
      "metadata": {
        "id": "6uTQ785jdpHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1"
      ],
      "metadata": {
        "id": "3L8BIUQtdsau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy6uYrOVdjta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2d02b4-545e-4770-c1c5-98133c191a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['anywh', 'becau', 'el', 'elsewh', 'everywh', 'ind', 'otherwi', 'plea', 'somewh'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing myvocab1:\n",
            "None\n",
            "Printing dtm1:\n",
            "  (0, 99)\t3\n",
            "  (0, 17)\t6\n",
            "  (0, 34)\t1\n",
            "  (0, 90)\t1\n",
            "  (0, 63)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 56)\t2\n",
            "  (0, 71)\t2\n",
            "  (0, 52)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 66)\t1\n",
            "  (0, 35)\t1\n",
            "  (0, 57)\t1\n",
            "  (0, 38)\t1\n",
            "  (0, 32)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 64)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 30)\t2\n",
            "  (0, 10)\t1\n",
            "  (0, 87)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 98)\t1\n",
            "  (1, 88)\t2\n",
            "  :\t:\n",
            "  (1143, 34)\t1\n",
            "  (1143, 52)\t1\n",
            "  (1143, 64)\t1\n",
            "  (1143, 88)\t1\n",
            "  (1143, 40)\t1\n",
            "  (1143, 3)\t2\n",
            "  (1143, 37)\t2\n",
            "  (1143, 89)\t1\n",
            "  (1143, 45)\t1\n",
            "  (1143, 13)\t1\n",
            "  (1143, 81)\t3\n",
            "  (1143, 21)\t1\n",
            "  (1144, 99)\t2\n",
            "  (1144, 1)\t1\n",
            "  (1144, 10)\t2\n",
            "  (1144, 69)\t1\n",
            "  (1144, 45)\t1\n",
            "  (1144, 27)\t1\n",
            "  (1144, 25)\t1\n",
            "  (1144, 95)\t1\n",
            "  (1144, 65)\t1\n",
            "  (1144, 48)\t3\n",
            "  (1144, 47)\t2\n",
            "  (1144, 80)\t1\n",
            "  (1144, 44)\t2\n",
            "Print pred_label_knn1:\n",
            "[0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
            " 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0\n",
            " 0 1 0 1 0 1 1]\n",
            "Printing accuracy_knn1:\n",
            "0.759825327510917\n",
            "Printing precision_knn1:\n",
            "0.7422680412371134\n",
            "Printing recall_knn1:\n",
            "0.7058823529411765\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#1.0 preprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from nltk.stem import PorterStemmer\n",
        "cv = CountVectorizer()\n",
        "ps = PorterStemmer()\n",
        "tv = TfidfVectorizer()\n",
        "from string import punctuation, digits\n",
        "import nltk\n",
        "import re\n",
        "import pickle\n",
        "import numpy\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# imports first, assignments below\n",
        "cv = CountVectorizer()\n",
        "ps = PorterStemmer()\n",
        "tv = TfidfVectorizer()\n",
        "\n",
        "\n",
        "# put file into dataframe\n",
        "df = pd.read_csv(\"news_label.csv\", encoding='latin1')\n",
        "docs = df[\"Message\"] # make a series, not a list, as a test\n",
        "labels = df[\"Class\"]\n",
        "\n",
        "\n",
        "# make preprocessing function\n",
        "def preprocess_text(text):\n",
        "  text = text.lower() #make everything lower case\n",
        "  text = text.translate(str.maketrans('','', digits)) # take out digits\n",
        "  text = text.translate(str.maketrans('','', punctuation)) # take out punctuation\n",
        "  text = re.sub(' +', ' ', text).strip() # remove extra spaces\n",
        "  t_list = text.split(\" \")\n",
        "  text = \" \".join(ps.stem(word) for word in t_list) #stemming\n",
        "  return text\n",
        "\n",
        "mystopwords = list(ENGLISH_STOP_WORDS)\n",
        "mystopwords.sort()\n",
        "stem_stopwords = [ps.stem(word) for word in mystopwords]\n",
        "\n",
        "\n",
        "cv = CountVectorizer(preprocessor=preprocess_text,\n",
        "                     stop_words = stem_stopwords,\n",
        "                     ngram_range=(1,1),\n",
        "                     max_df = docs.shape[0]-1,\n",
        "                     min_df = 2,\n",
        "                     max_features = 100)\n",
        "\n",
        "tv = TfidfVectorizer(preprocessor=preprocess_text,\n",
        "                      stop_words = stem_stopwords,\n",
        "                      norm=None,\n",
        "                      smooth_idf=False,\n",
        "                      ngram_range = (1,1),\n",
        "                      max_df=docs.shape[0]-1,\n",
        "                      max_features = 100)\n",
        "\n",
        "dtm1 = cv.fit_transform(docs)\n",
        "\n",
        "# 2.2 Ctf:\n",
        "terms = cv.get_feature_names_out()\n",
        "freq_sum = dtm.sum(axis=0)[0].tolist()[0] # list within a list to get 1st element\n",
        "Ctf = pd.DataFrame({\"terms\": terms,\n",
        "                    \"freq\": freq_sum})\n",
        "Ctf.sort_values(\"freq\",ascending=False,inplace=True)\n",
        "\n",
        "\n",
        "# 1.1\n",
        "dict1 = pd.DataFrame({\"terms\":terms, \"freq\":freq_sum})\n",
        "                  # freq at least 100\n",
        "myvocab1 = dict1.sort_values(\"freq\",ascending=False,inplace=True)\n",
        "print(\"Printing myvocab1:\")\n",
        "print(myvocab1)\n",
        "\n",
        "dtm11 = tv.fit_transform(docs) # for tv later\n",
        "\n",
        "# 1.2\n",
        "print(\"Printing dtm1:\")\n",
        "print(dtm1)\n",
        "\n",
        "# load partition\n",
        "with open(\"partition_hw4.pkl\", \"rb\") as f:\n",
        "  partition = pickle.load(f)\n",
        "  #print(partition)\n",
        "\n",
        "# convert to discrete labels to binary 0-1 labels\n",
        "num_labels = labels.replace([\"med\",\"space\"],[0,1])\n",
        "\n",
        "# convert sparse matrix to dataframe - sparse or dense matrix, depending\n",
        "dtm_df = pd.DataFrame(dtm.toarray(),columns=tv.get_feature_names_out())\n",
        "#print(\"Printing dtm_df:\",dtm_df)\n",
        "\n",
        "# testing modules - split data into training and testing\n",
        "train_df = df.iloc[partition[\"train_inds\"]]\n",
        "#print(train_df)\n",
        "test_df = df.iloc[partition[\"test_inds\"]]\n",
        "#print(test_df)\n",
        "\n",
        "train_text = train_df[\"Message\"].apply(preprocess_text)\n",
        "test_text =  test_df[\"Message\"].apply(preprocess_text)\n",
        "\n",
        "# convert discrete labels to binary 0-1 labels\n",
        "num_labels1 = labels.replace([\"med\", \"space\"],[0,1])\n",
        "\n",
        "# train-test split using indices\n",
        "# partition data\n",
        "train_inds = partition[\"train_inds\"] #ndarray\n",
        "test_inds = partition[\"test_inds\"] #list\n",
        "X_train = dtm_df.iloc[train_inds] #df\n",
        "X_test = dtm_df.iloc[test_inds] #df\n",
        "y_train = np.array(num_labels1)[train_inds] # ndarray\n",
        "y_test = np.array(num_labels1)[test_inds] # ndarray\n",
        "\n",
        "\n",
        "# train for KNN classifier\n",
        "k = 7\n",
        "kNN = KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train)\n",
        "test_pred = kNN.predict(X_test)\n",
        "#print(test_pred)\n",
        "\n",
        "# 1.3 test the KNN case \n",
        "pred_label_knn1 = kNN.predict(X_test)\n",
        "print(\"Print pred_label_knn1:\")\n",
        "print(pred_label_knn1)\n",
        "\n",
        "# 1.4 get accuracy of model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "knn_contable = confusion_matrix(y_test, test_pred, labels=[0,1])\n",
        "knn_disp = ConfusionMatrixDisplay(confusion_matrix=knn_contable, \n",
        "                                  display_labels=[0,1])\n",
        "accuracy_knn1 = (knn_contable[0,0] + knn_contable[1,1])/np.sum(knn_contable)\n",
        "accuracy_knn11 = kNN.score(X_test,y_test)\n",
        "print(\"Printing accuracy_knn1:\")\n",
        "print(accuracy_knn1)\n",
        "#print(accuracy_knn11) # yep, it matches exactly ^_^\n",
        "\n",
        "# 1.5\n",
        "precision_knn1 = precision_score(y_test, pred_label_knn1, pos_label = 1)\n",
        "print(\"Printing precision_knn1:\")\n",
        "print(precision_knn1)\n",
        "\n",
        "# 1.6\n",
        "recall_knn1 = recall_score(y_test, pred_label_knn1, pos_label = 1)\n",
        "print(\"Printing recall_knn1:\")\n",
        "print(recall_knn1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2"
      ],
      "metadata": {
        "id": "0lvxu1uSeGP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuation of problem 1:\n",
        "\n",
        "# Work to impore the kNN model, to get accuracy on the testing set to above 90%\n",
        "# K = 2 to 20 permutations didn't work and stayed at ~80%\n",
        "# train for KNN classifier:\n",
        "k_values = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
        "results = []\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(X_train, y_train)\n",
        "  test_pred = kNN.predict(X_test)\n",
        "  # 1.3 test the KNN case \n",
        "  pred_label_knn1 = knn.predict(X_test)\n",
        "  # 1.4 get accuracy of model\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import ConfusionMatrixDisplay\n",
        "  knn_contable = confusion_matrix(y_test, test_pred, labels=[0,1])\n",
        "  knn_disp = ConfusionMatrixDisplay(confusion_matrix=knn_contable, \n",
        "                                  display_labels=[0,1])\n",
        "  accuracy_knn1 = (knn_contable[0,0] + knn_contable[1,1])/np.sum(knn_contable)\n",
        "  #accuracy_knn11 = knn.score(X_test,y_test)\n",
        "  print(\"Printing accuracy_knn1:\")\n",
        "  print(accuracy_knn1)\n",
        "  #print(accuracy_knn11) # yep, it matches exactly ^_^\n",
        "  # 1.5\n",
        "  precision_knn1 = precision_score(y_test, pred_label_knn1, pos_label = 1)\n",
        "  print(\"Printing precision_knn1:\")\n",
        "  print(precision_knn1)\n",
        "  # 1.6\n",
        "  recall_knn1 = recall_score(y_test, pred_label_knn1, pos_label = 1)\n",
        "  print(\"Printing recall_knn1:\")\n",
        "  print(recall_knn1)\n",
        "\n",
        "# Work to improve model\n",
        "\n"
      ],
      "metadata": {
        "id": "prn3FOHzeIBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "ab285948-18d1-4d15-ab20-a3b55185987f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2683d1c8a5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3"
      ],
      "metadata": {
        "id": "AZbyqaxueWy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuation of problem 2:\n",
        "\n",
        "# Build neural network models\n",
        "\n",
        "# 3.1 h_val_auc:\n",
        "\n",
        "# 3.2 best_model:\n"
      ],
      "metadata": {
        "id": "QRSXPf-TeYLv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}